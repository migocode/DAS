{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "Source of code: https://github.com/sharmin2697/Movie-Recommender-System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import statistics\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import split\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import SVD\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0     196      242       3\n",
       "1     186      302       3\n",
       "2      22      377       1\n",
       "3     244       51       2\n",
       "4     166      346       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_index = [\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    "movie_index = [\"movieId\",\"title\",\"release_date\", \"video_release_dat\", \"IMDb_url\",\"unknown\", \"action\", \"adventure\", \"animation\", \"children\", \"comedy\", \"crime\", \"documentary\", \"drama\", \"fantasy\", \"film-noir\", \"horror\", \"musical\", \"mystery\", \"romance\", \"sci-fi\", \"thriller\", \"war\", \"western\"]\n",
    "ratings = pd.read_csv(r\"G:\\My Drive\\FH_Technikum\\MSC\\Semester_2_SS2022\\DAS\\Data\\ml-100k\\u.data\", sep=\"\\t\", names=rating_index)\n",
    "movies = pd.read_csv(r\"G:\\My Drive\\FH_Technikum\\MSC\\Semester_2_SS2022\\DAS\\Data\\ml-100k\\u.item\", sep=\"|\", names=movie_index, encoding='latin-1')\n",
    "movies = movies.drop([\"release_date\", \"video_release_dat\", \"IMDb_url\",\"unknown\", \"action\", \"adventure\", \"animation\", \"children\", \"comedy\", \"crime\", \"documentary\", \"drama\", \"fantasy\", \"film-noir\", \"horror\", \"musical\", \"mystery\", \"romance\", \"sci-fi\", \"thriller\", \"war\", \"western\"], axis=1)\n",
    "ratings = ratings.drop([\"timestamp\"], axis=1)\n",
    "\n",
    "data = ratings\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x287073f44f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "dataset = Dataset.load_from_df(data, reader)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items based collaborative filtering\n",
    "\n",
    "As a similarity measure I am chosing cosine. I use the K-nn algorithm taking into account the mean ratings of each user to counteract the differences in each users preference for maximum and minimum ratings (e.g. some user never give 5 out of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "datasets.append(train_test_split(dataset, test_size=0.2, random_state=547998))\n",
    "datasets.append(train_test_split(dataset, test_size=0.2))\n",
    "datasets.append(train_test_split(dataset, test_size=0.2))\n",
    "datasets.append(train_test_split(dataset, test_size=0.2))\n",
    "datasets.append(train_test_split(dataset, test_size=0.2))\n",
    "\n",
    "item_based = {'name': 'cosine',\n",
    "               'user_based': False} #defines if user-based filtering or items-based filtering should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8910\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8769\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8928\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8894\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8770\n",
      "Execution time: 26.100154161453247 seconds\n",
      "Mean mse: 0.8853872252800996\n"
     ]
    }
   ],
   "source": [
    "mse_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for (trainset, testset) in datasets:\n",
    "    algo = KNNWithMeans(100, 1, item_based)\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    mse = accuracy.mse(predictions)\n",
    "    mse_results.append(mse)\n",
    "\n",
    "print(\"Execution time: \" + str(time.time() - start_time) + \" seconds\")\n",
    "print(\"Mean mse: \" + str(statistics.mean(mse_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean value of the results (mean squared errors) is listed above. The values are rather stable and don't vary significantly. They also show a high predict accuracy (low mse).\n",
    "\n",
    "The algorithm performs well. It is not fast, but accurate all in all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User based collaborative filtering\n",
    "\n",
    "I am using the same algorithm and smilarity measure as with items based collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.9148\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.8998\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.9161\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.9152\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "MSE: 0.9049\n",
      "Execution time: 21.171416521072388 seconds\n",
      "Mean mse: 0.9101523294562632\n"
     ]
    }
   ],
   "source": [
    "mse_results = []\n",
    "\n",
    "user_based = {'name': 'cosine',\n",
    "               'user_based': True} #defines if user-based filtering or items-based filtering should be used\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for (trainset, testset) in datasets:\n",
    "    algo = KNNWithMeans(100, 1, user_based)\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    mse = accuracy.mse(predictions)\n",
    "    mse_results.append(mse)\n",
    "    \n",
    "print(\"Execution time: \" + str(time.time() - start_time) + \" seconds\")\n",
    "print(\"Mean mse: \" + str(statistics.mean(mse_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prediction accuracy (slightly higher mean mse) is significantly lower but the execution time is faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another model based approach collaborative filtering\n",
    "\n",
    "Another interesting (at least to me) algorithm seems to be CoClustering provided by surprise (https://surprise.readthedocs.io/en/stable/co_clustering.html#surprise.prediction_algorithms.co_clustering.CoClustering). Users and items are assigned some clusters. The clusters are generated similarly to k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mailb\\AppData\\Local\\Temp/ipykernel_18792/950404129.py:11: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  algo.fit(trainset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9329\n",
      "MSE: 0.9178\n",
      "MSE: 0.9588\n",
      "MSE: 0.9441\n",
      "MSE: 0.9146\n",
      "Execution time: 11.157257080078125 seconds\n",
      "Mean mse: 0.9336540574458415\n"
     ]
    }
   ],
   "source": [
    "mse_results = []\n",
    "\n",
    "user_based = {'name': 'cosine',\n",
    "               'user_based': True} #defines if user-based filtering or items-based filtering should be used\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for (trainset, testset) in datasets:\n",
    "    algo = CoClustering(random_state=547998)\n",
    "\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    mse = accuracy.mse(predictions)\n",
    "    mse_results.append(mse)\n",
    "    \n",
    "print(\"Execution time: \" + str(time.time() - start_time) + \" seconds\")\n",
    "print(\"Mean mse: \" + str(statistics.mean(mse_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm is the most efficient. It takes the least amount of time to generate the model and test. However, it has a worse accuracy than both prior methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all it can be stated that the prediction accuracy is stable amon all 5 splits but not very accurate (0.9). However, I am not certain as to where the threashold regarding an acceptable mse value lies. It is clear that the closer to 0 the better. Providing a fixed threshold for mse (e.g. 0.5) where everything below is acceptable seems arbitrary.\n",
    "\n",
    "Compared to processing the small datdaset, generating predictions with the large dataset did not yield considerably lower mean squared error values. This is rather surprising since one would expect a larger dataset to provide better models. This did not happen. Only the processing time increased rather massively."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4a1b88e3678edff03f97290122ff407750b5b5411c51ff5b4cc02ea4deb84ddf"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
